{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THESE LINES.\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from joblib import dump\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THESE LINES.\n",
    "ROOT_DIR = os.path.dirname(os.getcwd())\n",
    "MODEL_INPUTS_OUTPUTS = os.path.join(ROOT_DIR, 'model_inputs_outputs/')\n",
    "INPUT_DIR = os.path.join(MODEL_INPUTS_OUTPUTS, \"inputs\")\n",
    "INPUT_SCHEMA_DIR = os.path.join(INPUT_DIR, \"schema\")\n",
    "DATA_DIR = os.path.join(INPUT_DIR, \"data\")\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"training\")\n",
    "TEST_DIR = os.path.join(DATA_DIR, \"testing\")\n",
    "MODEL_PATH = os.path.join(MODEL_INPUTS_OUTPUTS, \"model\")\n",
    "MODEL_ARTIFACTS_PATH = os.path.join(MODEL_PATH, \"artifacts\")\n",
    "OHE_ENCODER_FILE = os.path.join(MODEL_ARTIFACTS_PATH, 'ohe.joblib')\n",
    "LABEL_ENCODER_FILE = os.path.join(MODEL_ARTIFACTS_PATH, 'label_encoder.joblib')\n",
    "PREDICTOR_DIR_PATH = os.path.join(MODEL_ARTIFACTS_PATH, \"predictor\")\n",
    "PREDICTOR_FILE_PATH = os.path.join(PREDICTOR_DIR_PATH, \"predictor.joblib\")\n",
    "IMPUTATION_FILE = os.path.join(MODEL_ARTIFACTS_PATH, 'imputation.joblib')\n",
    "if not os.path.exists(MODEL_ARTIFACTS_PATH):\n",
    "    os.makedirs(MODEL_ARTIFACTS_PATH)\n",
    "if not os.path.exists(PREDICTOR_DIR_PATH):\n",
    "    os.makedirs(PREDICTOR_DIR_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the schema\n",
    "The schema contains metadata about the datasets. We will use the schema to get information about the type of each feature (NUMERIC or CATEGORICAL) and the id and target features, this will be helpful in preprocessing stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = [f for f in os.listdir(INPUT_SCHEMA_DIR) if f.endswith('json')][0]\n",
    "schema_path = os.path.join(INPUT_SCHEMA_DIR, file_name)\n",
    "with open(schema_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    schema = json.load(file)\n",
    "features = schema['features']\n",
    "\n",
    "numeric_features = []\n",
    "categorical_features = []\n",
    "for f in features:\n",
    "    if f['dataType'] == 'CATEGORICAL':\n",
    "        categorical_features.append(f['name'])\n",
    "    else:\n",
    "        numeric_features.append(f['name'])\n",
    "\n",
    "id_feature = schema['id']['name']\n",
    "target_feature = schema['target']['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_id</th>\n",
       "      <th>fatals</th>\n",
       "      <th>a_ct</th>\n",
       "      <th>a_ped_f</th>\n",
       "      <th>a_pedal_f</th>\n",
       "      <th>a_roll</th>\n",
       "      <th>a_hr</th>\n",
       "      <th>a_polpur</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>...</th>\n",
       "      <th>owner</th>\n",
       "      <th>deaths</th>\n",
       "      <th>numoccs</th>\n",
       "      <th>impact1</th>\n",
       "      <th>deformed</th>\n",
       "      <th>ve_forms</th>\n",
       "      <th>ve_total</th>\n",
       "      <th>weather</th>\n",
       "      <th>lgt_cond</th>\n",
       "      <th>driver_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32083</td>\n",
       "      <td>1</td>\n",
       "      <td>Single-Vehicle Crash</td>\n",
       "      <td>Other Crash</td>\n",
       "      <td>Other Crash</td>\n",
       "      <td>Other Crash</td>\n",
       "      <td>No - Hit and Run</td>\n",
       "      <td>Other Crash</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Driver (in this crash) Was Registered Owner</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clockpoint 12</td>\n",
       "      <td>Disabling damage</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Dark - not lighted</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55073</td>\n",
       "      <td>1</td>\n",
       "      <td>Single-Vehicle Crash</td>\n",
       "      <td>Other Crash</td>\n",
       "      <td>Other Crash</td>\n",
       "      <td>Other Crash</td>\n",
       "      <td>No - Hit and Run</td>\n",
       "      <td>Other Crash</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>Driver (in this crash) Not Registered Owner (o...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clockpoint 1</td>\n",
       "      <td>Disabling damage</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Daylight</td>\n",
       "      <td>speeding_driver_involved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7458</td>\n",
       "      <td>1</td>\n",
       "      <td>Single-Vehicle Crash</td>\n",
       "      <td>Other Crash</td>\n",
       "      <td>Other Crash</td>\n",
       "      <td>Other Crash</td>\n",
       "      <td>No - Hit and Run</td>\n",
       "      <td>Other Crash</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>Driver (in this crash) Was Registered Owner</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clockpoint 12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Daylight</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5685</td>\n",
       "      <td>1</td>\n",
       "      <td>Single-Vehicle Crash</td>\n",
       "      <td>Other Crash</td>\n",
       "      <td>Other Crash</td>\n",
       "      <td>Other Crash</td>\n",
       "      <td>No - Hit and Run</td>\n",
       "      <td>Other Crash</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>Driver (in this crash) Not Registered Owner (o...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clockpoint 12</td>\n",
       "      <td>Functional damage</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Dark - not lighted</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9245</td>\n",
       "      <td>1</td>\n",
       "      <td>Single-Vehicle Crash</td>\n",
       "      <td>Other Crash</td>\n",
       "      <td>Other Crash</td>\n",
       "      <td>Other Crash</td>\n",
       "      <td>No - Hit and Run</td>\n",
       "      <td>Other Crash</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>Driver (in this crash) Was Registered Owner</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clockpoint 9</td>\n",
       "      <td>Disabling damage</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Dark - not lighted</td>\n",
       "      <td>drunk_driver_involved</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    u_id  fatals                  a_ct      a_ped_f    a_pedal_f       a_roll  \\\n",
       "0  32083       1  Single-Vehicle Crash  Other Crash  Other Crash  Other Crash   \n",
       "1  55073       1  Single-Vehicle Crash  Other Crash  Other Crash  Other Crash   \n",
       "2   7458       1  Single-Vehicle Crash  Other Crash  Other Crash  Other Crash   \n",
       "3   5685       1  Single-Vehicle Crash  Other Crash  Other Crash  Other Crash   \n",
       "4   9245       1  Single-Vehicle Crash  Other Crash  Other Crash  Other Crash   \n",
       "\n",
       "               a_hr     a_polpur  month  day  ...  \\\n",
       "0  No - Hit and Run  Other Crash     10    2  ...   \n",
       "1  No - Hit and Run  Other Crash      6   21  ...   \n",
       "2  No - Hit and Run  Other Crash      7   14  ...   \n",
       "3  No - Hit and Run  Other Crash      9   15  ...   \n",
       "4  No - Hit and Run  Other Crash      9   28  ...   \n",
       "\n",
       "                                               owner  deaths  numoccs  \\\n",
       "0        Driver (in this crash) Was Registered Owner       1      1.0   \n",
       "1  Driver (in this crash) Not Registered Owner (o...       1      1.0   \n",
       "2        Driver (in this crash) Was Registered Owner       0      1.0   \n",
       "3  Driver (in this crash) Not Registered Owner (o...       0      1.0   \n",
       "4        Driver (in this crash) Was Registered Owner       1      1.0   \n",
       "\n",
       "         impact1           deformed ve_forms ve_total weather  \\\n",
       "0  Clockpoint 12   Disabling damage        1        1   Clear   \n",
       "1   Clockpoint 1   Disabling damage        1        1   Clear   \n",
       "2  Clockpoint 12                NaN        1        1   Clear   \n",
       "3  Clockpoint 12  Functional damage        1        1   Clear   \n",
       "4   Clockpoint 9   Disabling damage        1        1   Clear   \n",
       "\n",
       "             lgt_cond             driver_factor  \n",
       "0  Dark - not lighted                     other  \n",
       "1            Daylight  speeding_driver_involved  \n",
       "2            Daylight                     other  \n",
       "3  Dark - not lighted                     other  \n",
       "4  Dark - not lighted     drunk_driver_involved  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = [f for f in os.listdir(TRAIN_DIR) if f.endswith('.csv')][0]\n",
    "file_path = os.path.join(TRAIN_DIR, file_name)\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Data preprocessing is very important before training the model, as the data may contain missing values in some cells. Moreover, most of the learning algorithms cannot work with categorical data, thus the data has to be encoded.\n",
    "\n",
    "In this section we will impute the missing values and encode the categorical features. Afterwards the data will be ready to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imputing missing data\n",
    "> In this section we imputed the missing values using the mode. However in many cases the mode is not an optimal value. You can try your own imputation and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/pparks/Dev/USD-HackAThon-2023-Fall/model_inputs_outputs/model/artifacts/imputation.joblib']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imputing missing data\n",
    "# columns_with_missing_values = df.columns[df.isna().any()]\n",
    "# imputaion_values = {}\n",
    "# for column in columns_with_missing_values:\n",
    "#     mode = df[column].mode()[0]\n",
    "#     df[column].fillna(mode, inplace=True)\n",
    "#     imputaion_values[column] = mode\n",
    "\n",
    "# path = dump(imputaion_values, IMPUTATION_FILE)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "numerical_cols_with_missing = [col for col in numeric_features if df[col].isna().any()]\n",
    "categorical_cols_with_missing = [col for col in categorical_features if df[col].isna().any()]\n",
    "\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')  # Mode imputation\n",
    "\n",
    "df[numerical_cols_with_missing] = knn_imputer.fit_transform(df[numerical_cols_with_missing])\n",
    "df[categorical_cols_with_missing] = categorical_imputer.fit_transform(df[categorical_cols_with_missing])\n",
    "\n",
    "imputers = {'numerical': knn_imputer, 'categorical': categorical_imputer}\n",
    "dump(imputers, IMPUTATION_FILE)\n",
    "\n",
    "\n",
    "# Comment the above code and write you own imputation code here\n",
    "\n",
    "# Different options I found for imputation\n",
    "# Handling NA values:\n",
    "# - Remove rows with NA values: \n",
    "#    df.dropna(inplace=True)\n",
    "# \n",
    "# - Replace NA values with a statistic (mean, median, or mode):\n",
    "#    df.fillna(df.mean(), inplace=True)\n",
    "# \n",
    "# - Use forward-fill or back-fill:\n",
    "#    df.fillna(method='ffill', inplace=True)\n",
    "#    # or\n",
    "#    df.fillna(method='bfill', inplace=True)\n",
    "# \n",
    "# - Replace NA values with a constant:\n",
    "#    df.fillna(-1, inplace=True)\n",
    "# \n",
    "# - Use interpolation:\n",
    "#    df.interpolate(inplace=True)\n",
    "\n",
    "# print(\"Size of the dataframe is \", df.shape)\n",
    "# rows_with_missing_values = df[df.isna().any(axis=1)]\n",
    "# path = dump(rows_with_missing_values, DROPNA_FILE)\n",
    "# df.dropna(inplace=True)\n",
    "# print(\"Size of the dataframe after removing dropna is \", df.shape)\n",
    "\n",
    "# I decided to just use the mode for imputation and focus on the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoding Categorical features\n",
    "> Notice that we do not want to encode the target feature nor the id column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the id and target columns in a different variable.\n",
    "ids = df[id_feature]\n",
    "target = df[target_feature]\n",
    "\n",
    "# Dropping the id and target from the dataframe\n",
    "df.drop(columns=[id_feature, target_feature], inplace=True)\n",
    "\n",
    "# Ensure that all categorical columns are stored as str type.\n",
    "# This is to ensure that even if the categories are numbers (1, 2, ...), they still get encoded.\n",
    "for c in categorical_features:\n",
    "    df[c] = df[c].astype(str)\n",
    "\n",
    "# Encoding the features\n",
    "encoder = OneHotEncoder(top_categories=6)\n",
    "encoder.fit(df)\n",
    "df = encoder.transform(df)\n",
    "\n",
    "# Saving the encoder to use it on the testing dataset\n",
    "path = dump(encoder, OHE_ENCODER_FILE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding the target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['other' 'speeding_driver_involved' 'other' ... 'other' 'other'\n",
      " 'drunk_driver_involved']\n"
     ]
    }
   ],
   "source": [
    "print(target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(target.values.reshape(-1, 1))\n",
    "dump(encoder, LABEL_ENCODER_FILE)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fatals</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>age</th>\n",
       "      <th>permvit</th>\n",
       "      <th>pernotmvit</th>\n",
       "      <th>mod_year</th>\n",
       "      <th>deaths</th>\n",
       "      <th>...</th>\n",
       "      <th>weather_Rain</th>\n",
       "      <th>weather_Fog, smog, smoke</th>\n",
       "      <th>weather_Snow</th>\n",
       "      <th>weather_Reported as unknown</th>\n",
       "      <th>lgt_cond_Daylight</th>\n",
       "      <th>lgt_cond_Dark - not lighted</th>\n",
       "      <th>lgt_cond_Dark - lighted</th>\n",
       "      <th>lgt_cond_Dawn</th>\n",
       "      <th>lgt_cond_Dark - unknown lighting</th>\n",
       "      <th>lgt_cond_Dusk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>8.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>21.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>20.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fatals  month  day  hour  minute  age  permvit  pernotmvit  mod_year  \\\n",
       "0       1     10    2   3.0    10.0   62        1           0    2003.0   \n",
       "1       1      6   21   8.0    45.0   40        1           0    2002.0   \n",
       "2       1      7   14  21.0    45.0   26        1           1    2003.0   \n",
       "3       1      9   15  20.0    46.0   64        1           1    1999.0   \n",
       "4       1      9   28  20.0    24.0   45        1           0    1996.0   \n",
       "\n",
       "   deaths  ...  weather_Rain  weather_Fog, smog, smoke  weather_Snow  \\\n",
       "0       1  ...             0                         0             0   \n",
       "1       1  ...             0                         0             0   \n",
       "2       0  ...             0                         0             0   \n",
       "3       0  ...             0                         0             0   \n",
       "4       1  ...             0                         0             0   \n",
       "\n",
       "   weather_Reported as unknown  lgt_cond_Daylight  \\\n",
       "0                            0                  0   \n",
       "1                            0                  1   \n",
       "2                            0                  1   \n",
       "3                            0                  0   \n",
       "4                            0                  0   \n",
       "\n",
       "   lgt_cond_Dark - not lighted  lgt_cond_Dark - lighted  lgt_cond_Dawn  \\\n",
       "0                            1                        0              0   \n",
       "1                            0                        0              0   \n",
       "2                            0                        0              0   \n",
       "3                            1                        0              0   \n",
       "4                            1                        0              0   \n",
       "\n",
       "   lgt_cond_Dark - unknown lighting  lgt_cond_Dusk  \n",
       "0                                 0              0  \n",
       "1                                 0              0  \n",
       "2                                 0              0  \n",
       "3                                 0              0  \n",
       "4                                 0              0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST CODE DO NOT LEAVE ENABLED\n",
    "if (is_debug):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42)\n",
    "    df = X_train\n",
    "    y = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Classifier\n",
    "We choose Logistic Regression Classifier, but feel free to try your own and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a logistic regression model and training it\n",
    "# model = LogisticRegression()\n",
    "# model.fit(df, y)\n",
    "# .63\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# model = RandomForestClassifier(n_estimators=100)\n",
    "# model.fit(df, y)\n",
    "# .67\n",
    "\n",
    "# from sklearn.svm import SVC\n",
    "# model = SVC(kernel='linear') # probability = False is MUCH faster\n",
    "# model = SVC(kernel='linear', probability=True)\n",
    "# Accuracy: 0.66\n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# model = KNeighborsClassifier(n_neighbors=5)\n",
    "# 0.57\n",
    "\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# model = GaussianNB()\n",
    "# 0.56\n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# model = DecisionTreeClassifier(max_leaf_nodes = 4, random_state = 0)\n",
    "# .64\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# model = GradientBoostingClassifier()\n",
    "# model = GradientBoostingClassifier(learning_rate=0.2, max_depth=3, n_estimators=100)\n",
    "best_params = {'subsample': 0.8, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 5, 'learning_rate': 0.1}\n",
    "model = GradientBoostingClassifier(**best_params)\n",
    "# 0.69\n",
    "\n",
    "train_params = False\n",
    "if (train_params):\n",
    "    # GradientBoostingClassifier worked the best with 0.69 accuracy\n",
    "    ## Try to tune for better accuracy\n",
    "    ## https://scikit-learn.org/stable/modules/grid_search.html\n",
    "    ## https://medium.com/all-things-ai/in-depth-parameter-tuning-for-gradient-boosting-3363992e9bae\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'max_features': ['auto', 'sqrt', 'log2']\n",
    "    }\n",
    "    # grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy')\n",
    "    # grid_search = GridSearchCV(model, param_grid, cv=3, scoring='f1_macro', n_jobs=-1)\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=100, cv=3, scoring='f1_macro')\n",
    "    random_search.fit(df, y)\n",
    "    best_params = random_search.best_params_\n",
    "    #{'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100}\n",
    "    # Initially I used scoring='accurary' but changed to scoring='f1_macro' after reading the docs\n",
    "    # The model is evaluated on Macro-averaged F1 Score\n",
    "    # grid_search.fit(df, y)\n",
    "    # best_params = grid_search.best_params_\n",
    "\n",
    "    print(best_params)\n",
    "    model = GradientBoostingClassifier(**best_params)\n",
    "\n",
    "\n",
    "model.fit(df, y)\n",
    "\n",
    "# Saving the model to use it for predictions\n",
    "path = dump(model, PREDICTOR_FILE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6959593729300066\n",
      "Macro Avg Precision: 0.6314455146693686\n",
      "Weighted Avg Precision: 0.6780284393927807\n",
      "Macro Avg Recall: 0.578229313113034\n",
      "Weighted Avg Recall: 0.6959593729300066\n",
      "Macro Avg F1-Score: 0.583618563900676\n",
      "Weighted Avg F1-Score: 0.6750943335237147\n",
      "Weighted Avg AUC-Score: 0.8285459687176149\n"
     ]
    }
   ],
   "source": [
    "# TEST CODE DO NOT LEAVE ENABLED\n",
    "if (is_debug):\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Get predicted probabilities\n",
    "    y_pred_prob = model.predict_proba(X_test)\n",
    "\n",
    "    # Calculate the metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "    precision_w, recall_w, f1_score_w, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_prob, average='weighted', multi_class='ovr')\n",
    "    \n",
    "    print('Accuracy:', accuracy)\n",
    "    print('Macro Avg Precision:', precision)\n",
    "    print('Weighted Avg Precision:', precision_w)\n",
    "    print('Macro Avg Recall:', recall)\n",
    "    print('Weighted Avg Recall:', recall_w)\n",
    "    print('Macro Avg F1-Score:', f1_score)\n",
    "    print('Weighted Avg F1-Score:', f1_score_w)\n",
    "    print('Weighted Avg AUC-Score:', roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISABLE THE DEBUG FLAG BEFORE SUBMITTING THE NOTEBOOK!\n"
     ]
    }
   ],
   "source": [
    "if (is_debug):\n",
    "    print(\"DISABLE THE DEBUG FLAG BEFORE SUBMITTING THE NOTEBOOK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Accuracy: 0.6920953852947671\n",
    "# Macro Avg Precision: 0.6237889355795457\n",
    "# Weighted Avg Precision: 0.6733327232094176\n",
    "# Macro Avg Recall: 0.5755847767475675\n",
    "# Weighted Avg Recall: 0.6920953852947671\n",
    "# Macro Avg F1-Score: 0.5803224831418862\n",
    "# Weighted Avg F1-Score: 0.671840351900582\n",
    "# Weighted Avg AUC-Score: 0.828581996716839"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
